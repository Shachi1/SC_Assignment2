{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SC-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKiFK0CoBtAj",
        "outputId": "f4b0fd90-48a6-4416-a68a-366ca3501bb3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UMKTgRoeqfW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RManlEUee0_s"
      },
      "source": [
        "# url = '/content/drive/MyDrive/Colab Notebooks/Dataset/Dataset C/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC1Mh0lIGogh"
      },
      "source": [
        "# dataset_A = url + 'Dataset A.zip'\n",
        "# with ZipFile(dataset_A, 'r') as zip:\n",
        "#   zip.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "xy-Cey0sf9Fz",
        "outputId": "0ec8f960-47dd-425c-d721-225cf2cd2013"
      },
      "source": [
        "data_labels = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dataset/Dataset C/training-c.csv', usecols = ['filename', 'digit'])\n",
        "print(data_labels.shape)\n",
        "data_labels.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24298, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c00000.png</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c00001.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c00002.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c00003.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c00004.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     filename  digit\n",
              "0  c00000.png      6\n",
              "1  c00001.png      1\n",
              "2  c00002.png      3\n",
              "3  c00003.png      2\n",
              "4  c00004.png      7"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTJ2ocEEHVGA"
      },
      "source": [
        "\n",
        "TRAIN_PATH = '/content/drive/MyDrive/Colab Notebooks/Dataset/Dataset C/training-c'\n",
        "# os.mkdir(TRAIN_PATH)\n",
        "\n",
        "# def processImages(folder_name):\n",
        "#   src = PATH + folder_name + '/'\n",
        "#   dir_folders = os.listdir(src)\n",
        "#   for dir_name in dir_folders:\n",
        "#     file_name = os.path.join(src, dir_name)\n",
        "#     if os.path.isfile(file_name):\n",
        "#       shutil.copy(file_name, TRAIN_PATH) \n",
        "\n",
        "# processImages('training-c')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmE05jA4kTDU"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, df, root, transform=None):\n",
        "        self.data = df\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.data.iloc[index]\n",
        "        \n",
        "        path = self.root + \"/\" + item[0]\n",
        "        image = Image.open(path).convert('L')\n",
        "        label = item[1]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adaZ60Uik-eb",
        "outputId": "22b53955-4efb-4b8e-dd43-b8adc62d509f"
      },
      "source": [
        "mean = [0.5,]\n",
        "std = [0.5, ]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(180),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(180),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_data  = Dataset(data_labels, TRAIN_PATH, train_transform)\n",
        "test_data = Dataset(data_labels, TRAIN_PATH, test_transform)\n",
        "\n",
        "print(\"Trainig Samples: \", len(train_data))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainig Samples:  24298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBXW2_0YUmzN",
        "outputId": "3817bcdf-129b-446a-be46-de0d944fd665"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.Dataset at 0x7f08f4227810>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8htM9w2LmUVl"
      },
      "source": [
        "Experiment: 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGG3l4vrmkI3",
        "outputId": "66ba1133-2cb0-4b4c-904c-1c772ce1267d"
      },
      "source": [
        "batch_size = 20\n",
        "num_iters = 20000\n",
        "input_dim = 180*180 # num_features \n",
        "num_hidden = 200 # num of hidden nodes\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsSesapsltZF",
        "outputId": "28a53c7a-8297-4126-f2e0-689377caed7b"
      },
      "source": [
        "test_size = 0.2\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:486\n",
            "Test dataloader:122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jCcU8giniGS"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "       \n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        self.relu_1 = nn.ReLU()\n",
        " \n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_2 = nn.ReLU()\n",
        " \n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_3 = nn.ReLU()\n",
        " \n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_4 = nn.ReLU()\n",
        " \n",
        "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_5= nn.ReLU()\n",
        " \n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_6 = nn.ReLU()\n",
        " \n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out  = self.linear_1(x)\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        out  = self.linear_2(out)\n",
        "        out = self.relu_2(out)\n",
        " \n",
        "        out  = self.linear_3(out)\n",
        "        out = self.relu_3(out)\n",
        " \n",
        "        out  = self.linear_4(out)\n",
        "        out = self.relu_4(out)\n",
        " \n",
        "        out  = self.linear_5(out)\n",
        "        out = self.relu_5(out)\n",
        " \n",
        "        out  = self.linear_6(out)\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q23HotHio42L",
        "outputId": "5f6dfe56-49c2-41b4-e137-b71ce9052d56"
      },
      "source": [
        "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): ReLU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): ReLU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): ReLU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): ReLU()\n",
              "  (linear_5): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_5): ReLU()\n",
              "  (linear_6): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_6): ReLU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1YagXSipEth"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kc10bu_Yd-_"
      },
      "source": [
        "# gh=1\n",
        "# for i, (images, labels) in enumerate(train_loader):\n",
        "#   print(images, labels)\n",
        "#   gh=gh+1\n",
        "#   if gh >= 1:\n",
        "#     break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VJ_sYCMp2l9"
      },
      "source": [
        "def epoch_func(num_epochs,train_loader,test_loader):\n",
        "  iteration_loss = []\n",
        "  iter = 0\n",
        "  for epoch in range(num_epochs):\n",
        "      print('Epoch: ', epoch + 1)\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "          images = images.view(-1, 180*180).to(device)\n",
        "          labels = labels.to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          outputs = model(images) \n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          iter += 1\n",
        "\n",
        "          if iter % 500 == 0:        \n",
        "              correct = 0\n",
        "              total = 0\n",
        "              for images, labels in test_loader:\n",
        "                \n",
        "                  images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                  outputs = model(images)\n",
        "\n",
        "                  _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                  total += labels.size(0)\n",
        "\n",
        "                  if torch.cuda.is_available():\n",
        "                      correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                  else:\n",
        "                      correct += (predicted == labels).sum()\n",
        "\n",
        "              accuracy = 100 * correct.item() / total\n",
        "\n",
        "              iteration_loss.append(loss.item())\n",
        "              print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeoTY6_RtR4c"
      },
      "source": [
        "epoch_func(num_epochs,train_loader,test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwU44FpRqO9t"
      },
      "source": [
        "# torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/model_base.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "1AIS0RVwq8ul",
        "outputId": "8eed53f6-a954-421e-d854-89986f5a022d"
      },
      "source": [
        "print (iteration_loss)\n",
        "plt.plot(iteration_loss)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.3034706115722656, 2.2987241744995117, 2.301450729370117, 2.3012654781341553, 2.2996795177459717, 2.3097803592681885, 2.294081449508667, 2.2955873012542725, 2.236278533935547, 2.3110880851745605, 2.256373405456543, 2.170766830444336, 1.9849979877471924, 2.2417988777160645, 2.4874377250671387, 2.2344374656677246, 2.187920093536377, 2.214724063873291, 2.1284072399139404, 2.5534698963165283, 2.303806781768799, 2.2291712760925293, 1.8404605388641357, 2.132941246032715, 1.9581797122955322, 2.216296434402466, 1.6052658557891846, 1.7953771352767944, 1.7786626815795898, 1.6191895008087158, 1.91265070438385]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhGqQ4vv47a4"
      },
      "source": [
        "# model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/model_base.pkl'))\n",
        "# model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8qNdcFbwVC6"
      },
      "source": [
        "Experiment: 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vju8t-3WQpC"
      },
      "source": [
        "batch_size = 40\n",
        "num_iters = 40000\n",
        "input_dim = 180*180 # num_features \n",
        "num_hidden = 200 # num of hidden nodes\n",
        "output_dim = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "num_epochs = int(num_iters / (len(train_data) / batch_size))\n",
        "print(num_epochs)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "       \n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        self.relu_1 = nn.ReLU()\n",
        " \n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_2 = nn.ReLU()\n",
        " \n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_3 = nn.ReLU()\n",
        " \n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_4 = nn.ReLU()\n",
        " \n",
        "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_5= nn.ReLU()\n",
        " \n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_6 = nn.ReLU()\n",
        " \n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out  = self.linear_1(x)\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        out  = self.linear_2(out)\n",
        "        out = self.relu_2(out)\n",
        " \n",
        "        out  = self.linear_3(out)\n",
        "        out = self.relu_3(out)\n",
        " \n",
        "        out  = self.linear_4(out)\n",
        "        out = self.relu_4(out)\n",
        " \n",
        "        out  = self.linear_5(out)\n",
        "        out = self.relu_5(out)\n",
        " \n",
        "        out  = self.linear_6(out)\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)     \n",
        "epoch_func(num_epochs,train_loader,test_loader)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2TxfYiptOmW",
        "outputId": "f15d1092-a167-41f8-f301-fe0f2d887e1c"
      },
      "source": [
        "batch_size = 40\n",
        "num_iters = 40000\n",
        "input_dim = 180*180 # num_features \n",
        "num_hidden = 200 # num of hidden nodes\n",
        "output_dim = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "num_epochs = int(num_iters / (len(train_data) / batch_size))\n",
        "print(num_epochs)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "       \n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        self.relu_1 = nn.Sigmoid()\n",
        " \n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_2 = nn.Sigmoid()\n",
        " \n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_3 = nn.Sigmoid()\n",
        " \n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_4 = nn.Sigmoid()\n",
        " \n",
        "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_5= nn.Sigmoid()\n",
        " \n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_6 = nn.Sigmoid()\n",
        " \n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out  = self.linear_1(x)\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        out  = self.linear_2(out)\n",
        "        out = self.relu_2(out)\n",
        " \n",
        "        out  = self.linear_3(out)\n",
        "        out = self.relu_3(out)\n",
        " \n",
        "        out  = self.linear_4(out)\n",
        "        out = self.relu_4(out)\n",
        " \n",
        "        out  = self.linear_5(out)\n",
        "        out = self.relu_5(out)\n",
        " \n",
        "        out  = self.linear_6(out)\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)     \n",
        "epoch_func(num_epochs,train_loader,test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RPjcD_lnd0QK",
        "outputId": "76c93622-17f9-40e8-9ed0-228e891e6164"
      },
      "source": [
        "batch_size = 20\n",
        "num_iters = 40000\n",
        "input_dim = 180*180 # num_features \n",
        "num_hidden = 300 # num of hidden nodes\n",
        "output_dim = 10\n",
        "learning_rate = 0.05\n",
        "\n",
        "num_epochs = int(num_iters / (len(train_data) / batch_size))\n",
        "print(num_epochs)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "       \n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        self.relu_1 = nn.Tanh()\n",
        " \n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_2 = nn.Tanh()\n",
        " \n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_3 = nn.Tanh()\n",
        " \n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_4 = nn.Tanh()\n",
        " \n",
        "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_5= nn.Tanh()\n",
        " \n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_6 = nn.Tanh()\n",
        " \n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out  = self.linear_1(x)\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        out  = self.linear_2(out)\n",
        "        out = self.relu_2(out)\n",
        " \n",
        "        out  = self.linear_3(out)\n",
        "        out = self.relu_3(out)\n",
        " \n",
        "        out  = self.linear_4(out)\n",
        "        out = self.relu_4(out)\n",
        " \n",
        "        out  = self.linear_5(out)\n",
        "        out = self.relu_5(out)\n",
        " \n",
        "        out  = self.linear_6(out)\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)     \n",
        "epoch_func(num_epochs,train_loader,test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32\n",
            "Epoch:  1\n",
            "Iteration: 500. Loss: 2.309987783432007. Accuracy: 10.413665363243465\n",
            "Epoch:  2\n",
            "Iteration: 1000. Loss: 2.294351100921631. Accuracy: 10.51656719489607\n",
            "Iteration: 1500. Loss: 2.2789862155914307. Accuracy: 16.27906976744186\n",
            "Epoch:  3\n",
            "Iteration: 2000. Loss: 2.3391919136047363. Accuracy: 11.360362214447417\n",
            "Iteration: 2500. Loss: 2.3137359619140625. Accuracy: 9.6521918090142\n",
            "Epoch:  4\n",
            "Iteration: 3000. Loss: 2.3055806159973145. Accuracy: 13.089112986211154\n",
            "Iteration: 3500. Loss: 2.324286460876465. Accuracy: 11.010495986828566\n",
            "Epoch:  5\n",
            "Iteration: 4000. Loss: 2.281212329864502. Accuracy: 9.487548878370035\n",
            "Iteration: 4500. Loss: 2.3057291507720947. Accuracy: 12.574603827948138\n",
            "Epoch:  6\n",
            "Iteration: 5000. Loss: 2.309100389480591. Accuracy: 11.916032105371476\n",
            "Iteration: 5500. Loss: 2.295259714126587. Accuracy: 10.290183165260341\n",
            "Epoch:  7\n",
            "Iteration: 6000. Loss: 2.307016372680664. Accuracy: 9.672772175344722\n",
            "Iteration: 6500. Loss: 2.278212308883667. Accuracy: 18.131302737188722\n",
            "Epoch:  8\n",
            "Iteration: 7000. Loss: 2.306317090988159. Accuracy: 9.6521918090142\n",
            "Iteration: 7500. Loss: 2.323970317840576. Accuracy: 10.166700967277217\n",
            "Epoch:  9\n",
            "Iteration: 8000. Loss: 2.2836813926696777. Accuracy: 10.063799135624613\n",
            "Iteration: 8500. Loss: 2.3507018089294434. Accuracy: 10.125540234616176\n",
            "Epoch:  10\n",
            "Iteration: 9000. Loss: 2.2919609546661377. Accuracy: 10.290183165260341\n",
            "Iteration: 9500. Loss: 2.3546030521392822. Accuracy: 13.336077382177402\n",
            "Epoch:  11\n",
            "Iteration: 10000. Loss: 2.3019115924835205. Accuracy: 10.331343897921384\n",
            "Iteration: 10500. Loss: 2.296912431716919. Accuracy: 10.331343897921384\n",
            "Epoch:  12\n",
            "Iteration: 11000. Loss: 2.2916293144226074. Accuracy: 10.825272689853879\n",
            "Iteration: 11500. Loss: 2.2820773124694824. Accuracy: 16.48487343074707\n",
            "Epoch:  13\n",
            "Iteration: 12000. Loss: 2.3675460815429688. Accuracy: 10.763531590862318\n",
            "Iteration: 12500. Loss: 2.290865659713745. Accuracy: 13.747684708787816\n",
            "Epoch:  14\n",
            "Iteration: 13000. Loss: 2.3101441860198975. Accuracy: 9.693352541675242\n",
            "Iteration: 13500. Loss: 2.288900852203369. Accuracy: 9.775674006997324\n",
            "Epoch:  15\n",
            "Iteration: 14000. Loss: 2.31980037689209. Accuracy: 11.4426836797695\n",
            "Iteration: 14500. Loss: 2.3027939796447754. Accuracy: 15.126569252932702\n",
            "Epoch:  16\n",
            "Iteration: 15000. Loss: 2.3108763694763184. Accuracy: 10.948754887837003\n",
            "Iteration: 15500. Loss: 2.296062707901001. Accuracy: 10.104959868285656\n",
            "Epoch:  17\n",
            "Iteration: 16000. Loss: 2.2803330421447754. Accuracy: 9.878575838649928\n",
            "Iteration: 16500. Loss: 2.3004679679870605. Accuracy: 10.26960279892982\n",
            "Epoch:  18\n",
            "Iteration: 17000. Loss: 2.3002352714538574. Accuracy: 10.393084996912945\n",
            "Epoch:  19\n",
            "Iteration: 17500. Loss: 2.3095860481262207. Accuracy: 13.171434451533237\n",
            "Iteration: 18000. Loss: 2.2880406379699707. Accuracy: 9.425807779378474\n",
            "Epoch:  20\n",
            "Iteration: 18500. Loss: 2.2907204627990723. Accuracy: 9.6521918090142\n",
            "Iteration: 19000. Loss: 2.280512571334839. Accuracy: 10.701790491870755\n",
            "Epoch:  21\n",
            "Iteration: 19500. Loss: 2.306602954864502. Accuracy: 15.414694381559991\n",
            "Iteration: 20000. Loss: 2.315507173538208. Accuracy: 12.615764560609179\n",
            "Epoch:  22\n",
            "Iteration: 20500. Loss: 2.3248796463012695. Accuracy: 9.487548878370035\n",
            "Iteration: 21000. Loss: 2.301345109939575. Accuracy: 11.380942580777937\n",
            "Epoch:  23\n",
            "Iteration: 21500. Loss: 2.314370632171631. Accuracy: 10.969335254167524\n",
            "Iteration: 22000. Loss: 2.2716128826141357. Accuracy: 10.393084996912945\n",
            "Epoch:  24\n",
            "Iteration: 22500. Loss: 2.2818613052368164. Accuracy: 10.104959868285656\n",
            "Iteration: 23000. Loss: 2.284059524536133. Accuracy: 9.672772175344722\n",
            "Epoch:  25\n",
            "Iteration: 23500. Loss: 2.2857844829559326. Accuracy: 9.796254373327844\n",
            "Iteration: 24000. Loss: 2.2879858016967773. Accuracy: 10.290183165260341\n",
            "Epoch:  26\n",
            "Iteration: 24500. Loss: 2.307952880859375. Accuracy: 9.6521918090142\n",
            "Iteration: 25000. Loss: 2.3285152912139893. Accuracy: 10.331343897921384\n",
            "Epoch:  27\n",
            "Iteration: 25500. Loss: 2.3462626934051514. Accuracy: 10.146120600946697\n",
            "Iteration: 26000. Loss: 2.318161725997925. Accuracy: 11.46326404610002\n",
            "Epoch:  28\n",
            "Iteration: 26500. Loss: 2.2790579795837402. Accuracy: 13.500720312821569\n",
            "Iteration: 27000. Loss: 2.292452335357666. Accuracy: 13.027371887219592\n",
            "Epoch:  29\n",
            "Iteration: 27500. Loss: 2.2957732677459717. Accuracy: 10.495986828565549\n",
            "Iteration: 28000. Loss: 2.2870516777038574. Accuracy: 11.48384441243054\n",
            "Epoch:  30\n",
            "Iteration: 28500. Loss: 2.293855905532837. Accuracy: 10.166700967277217\n",
            "Iteration: 29000. Loss: 2.2827231884002686. Accuracy: 10.310763531590862\n",
            "Epoch:  31\n",
            "Iteration: 29500. Loss: 2.2924537658691406. Accuracy: 14.118131302737188\n",
            "Iteration: 30000. Loss: 2.315001964569092. Accuracy: 10.125540234616176\n",
            "Epoch:  32\n",
            "Iteration: 30500. Loss: 2.2958908081054688. Accuracy: 10.640049392879193\n",
            "Iteration: 31000. Loss: 2.2892675399780273. Accuracy: 11.833710640049393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM6f5taG0Xiu"
      },
      "source": [
        "Experiment: 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "P0rI1lU9w56I",
        "outputId": "3fbeaffe-ac30-45ca-ada3-5c91c3377001"
      },
      "source": [
        "df2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dataset/Dataset_2/verification_train.csv')\n",
        "print(df2.shape)\n",
        "df2.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 785)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      2       0       0       0  ...         0         0         0         0\n",
              "1      9       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[2 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "E8p5t5K-g0kx",
        "outputId": "3920c788-5710-4427-f792-c83d66c0af4f"
      },
      "source": [
        "df3 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dataset/Dataset_2/verification_test.csv')\n",
        "print(df3.shape)\n",
        "df3.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 785)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>242</td>\n",
              "      <td>245</td>\n",
              "      <td>224</td>\n",
              "      <td>245</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>69</td>\n",
              "      <td>94</td>\n",
              "      <td>123</td>\n",
              "      <td>127</td>\n",
              "      <td>138</td>\n",
              "      <td>138</td>\n",
              "      <td>142</td>\n",
              "      <td>145</td>\n",
              "      <td>135</td>\n",
              "      <td>125</td>\n",
              "      <td>103</td>\n",
              "      <td>87</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>209</td>\n",
              "      <td>190</td>\n",
              "      <td>181</td>\n",
              "      <td>150</td>\n",
              "      <td>170</td>\n",
              "      <td>193</td>\n",
              "      <td>180</td>\n",
              "      <td>219</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>248</td>\n",
              "      <td>238</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>233</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>235</td>\n",
              "      <td>216</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      0       0       0       0  ...         0         0         0         0\n",
              "1      1       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[2 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82DZ6gk5akX-"
      },
      "source": [
        "train2 = []\n",
        "test2 = []\n",
        "label1 = []\n",
        "label2 = []\n",
        "\n",
        "for i in range(10) :\n",
        "  nary = np.array(df2.iloc[i])\n",
        "  label1.append(nary[0])\n",
        "  train2.append(np.delete(nary,0).reshape(28,28))\n",
        "\n",
        "\n",
        "for i in range(10) :\n",
        "  nary = np.array(df2.iloc[i])\n",
        "  label2.append(nary[0])\n",
        "  test2.append(np.delete(nary,0).reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzSYAkzplKW9"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "tensor = torch.Tensor(nary) # transform to torch tensor\n",
        "my_dataset = TensorDataset(tensor) # create your datset\n",
        "train_loader2 = DataLoader(my_dataset)\n",
        "\n",
        "tensor = torch.Tensor(nary) # transform to torch tensor\n",
        "my_dataset = TensorDataset(tensor) # create your datset\n",
        "test_loader2 = DataLoader(my_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBgcF3VWmbLM"
      },
      "source": [
        "batch_size = 30\n",
        "num_iters = 40000\n",
        "input_dim = 180*180 # num_features \n",
        "num_hidden = 200 # num of hidden nodes\n",
        "output_dim = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "num_epochs = int(num_iters / (len(train_data) / batch_size))\n",
        "print(num_epochs)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "       \n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        self.relu_1 = nn.ReLU()\n",
        " \n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_2 = nn.ReLU()\n",
        " \n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_3 = nn.ReLU()\n",
        " \n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_4 = nn.ReLU()\n",
        " \n",
        "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_5= nn.ReLU()\n",
        " \n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.relu_6 = nn.ReLU()\n",
        " \n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out  = self.linear_1(x)\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        out  = self.linear_2(out)\n",
        "        out = self.relu_2(out)\n",
        " \n",
        "        out  = self.linear_3(out)\n",
        "        out = self.relu_3(out)\n",
        " \n",
        "        out  = self.linear_4(out)\n",
        "        out = self.relu_4(out)\n",
        " \n",
        "        out  = self.linear_5(out)\n",
        "        out = self.relu_5(out)\n",
        " \n",
        "        out  = self.linear_6(out)\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)     \n",
        "epoch_func(num_epochs,train_loader2,test_loader2)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}